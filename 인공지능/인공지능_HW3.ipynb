{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTfQxLv5R5Xu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e37c6612-ad55-44e0-884a-c576ffff2d05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 1.3543 - accuracy: 0.3750\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.3522 - accuracy: 0.2500\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.3499 - accuracy: 0.3750\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.3478 - accuracy: 0.3750\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3460 - accuracy: 0.3750\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.3446 - accuracy: 0.3750\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.3430 - accuracy: 0.3750\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.3413 - accuracy: 0.3750\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.3396 - accuracy: 0.3750\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3379 - accuracy: 0.3750\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.3362 - accuracy: 0.3750\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.3346 - accuracy: 0.3750\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.3331 - accuracy: 0.5000\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.3315 - accuracy: 0.5000\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3300 - accuracy: 0.5000\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3286 - accuracy: 0.5000\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.3272 - accuracy: 0.5000\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.3258 - accuracy: 0.6250\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.3242 - accuracy: 0.6250\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3226 - accuracy: 0.6250\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.3210 - accuracy: 0.6250\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.3193 - accuracy: 0.6250\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.3176 - accuracy: 0.6250\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.3159 - accuracy: 0.6250\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3142 - accuracy: 0.6250\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3125 - accuracy: 0.6250\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3108 - accuracy: 0.6250\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.3091 - accuracy: 0.6250\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3075 - accuracy: 0.6250\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.3059 - accuracy: 0.6250\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.3041 - accuracy: 0.6250\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 1.3023 - accuracy: 0.6250\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.3005 - accuracy: 0.6250\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.2989 - accuracy: 0.6250\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.2972 - accuracy: 0.6250\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.2955 - accuracy: 0.6250\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2937 - accuracy: 0.6250\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.2919 - accuracy: 0.6250\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2901 - accuracy: 0.6250\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2883 - accuracy: 0.6250\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2865 - accuracy: 0.6250\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2846 - accuracy: 0.6250\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2827 - accuracy: 0.6250\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2808 - accuracy: 0.6250\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.2789 - accuracy: 0.6250\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2769 - accuracy: 0.6250\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2750 - accuracy: 0.6250\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2731 - accuracy: 0.6250\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2710 - accuracy: 0.6250\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2690 - accuracy: 0.6250\n",
            "Test\n",
            "0 0 0 0\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "입력 데이터의 예측값은  solid  입니다.\n"
          ]
        }
      ],
      "source": [
        "# 2번\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "x = [[1, 1, 1, 1], [0, 0, 0, 0], [1, 0, 1, 0], [0, 1, 0, 1], [1, 0, 0, 1], [0, 1, 1, 0], [0, 0, 1, 1], [1, 1, 0, 0]]\n",
        "y = [0,0,1,1,2,2,3,3]\n",
        "y_label = ['solid', 'vertical', 'diaglonal', 'horizontal'] # test시 사용할 라벨 이름\n",
        "x = np.array(x)\n",
        "y = np.array(y)\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Dense(16, activation='relu', input_shape=(4,)))\n",
        "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(4, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print(\"Train\")\n",
        "model.fit(x, y, epochs=50)\n",
        "\n",
        "print(\"Test\")\n",
        "x_input = [list(map(float, input().split()))]\n",
        "y_pred = model.predict(x_input)\n",
        "print(\"입력 데이터의 예측값은 \", y_label[np.argmax(y_pred)], \" 입니다.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3번 - MLP\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fashion_data = tf.keras.datasets.fashion_mnist\n",
        "(x_train, y_train), (x_test, y_test) = fashion_data.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
        "model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "id": "XWLGIq1GYagC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b4e19cb-16c5-4d2a-d545-95cb99c6b9a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.4770 - accuracy: 0.8300\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 0.3586 - accuracy: 0.8687\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3211 - accuracy: 0.8824\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2975 - accuracy: 0.8898\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2790 - accuracy: 0.8975\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3363 - accuracy: 0.8787\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3362857401371002, 0.8787000179290771]"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3번 - 심층신경망\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fashion_data = tf.keras.datasets.fashion_mnist\n",
        "(x_train, y_train), (x_test, y_test) = fashion_data.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
        "model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bz0CVDzT88T",
        "outputId": "d3784c53-766c-4b83-f88b-06e1aa02e229"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.4882 - accuracy: 0.8236\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.3685 - accuracy: 0.8641\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 0.3321 - accuracy: 0.8775\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 12s 7ms/step - loss: 0.3082 - accuracy: 0.8865\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 12s 7ms/step - loss: 0.2917 - accuracy: 0.8907\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3633 - accuracy: 0.8717\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.36332830786705017, 0.8716999888420105]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4번\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import datasets # 끝에 's'\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "\n",
        "x = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# 80:20\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=4)\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Dense(32, activation='relu', input_shape=(4,))) # 입력층은 특징벡터\n",
        "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(3, activation='softmax')) # 꽃 종류 3개 이므로\n",
        "\n",
        "# sparse_categorical_crossentropy : 자동으로 원핫 인코딩\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=50)\n",
        "print('=========prediction========')\n",
        "print(model.predict(x_test))\n",
        "print('=========evaluate========')\n",
        "print(model.evaluate(x_test, y_test))\n",
        "\n",
        "classes = {0 : 'setosa', 1 : 'versicolor', 2 : 'virginica'}\n",
        "# 2차원 리스트로 입력 받아야함\n",
        "# 특징 4개가 input -> shape = [4 x 1]\n",
        "x_input = [list(map(float, input().split()))]\n",
        "print(x_input)\n",
        "# output은 꽃 3종류 -> shape = [3 x 1]\n",
        "y_pred = model.predict(x_input)\n",
        "print(y_pred)\n",
        "# 3개 중에 가장 높게 예측된 값이 모델이 예측한 값\n",
        "y_max = y_pred[0][0]\n",
        "max_index = 0\n",
        "\n",
        "for i in range(1,3):\n",
        "  if y_pred[0][i] > y_max:\n",
        "    max_index = i\n",
        "\n",
        "print(\"모델이 예측한 값은 \", classes[max_index], \" 입니다.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIvxqh9WZAR7",
        "outputId": "8b93f178-03c7-48a6-b422-716b10c71684"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.8288 - accuracy: 0.0500\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.5558 - accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.3970 - accuracy: 0.2500\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.2988 - accuracy: 0.3667\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.2429 - accuracy: 0.4167\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.2019 - accuracy: 0.4750\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.1594 - accuracy: 0.5000\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.1130 - accuracy: 0.5083\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0676 - accuracy: 0.5333\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0227 - accuracy: 0.5250\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9881 - accuracy: 0.5333\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9485 - accuracy: 0.5500\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9135 - accuracy: 0.7167\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8792 - accuracy: 0.8333\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8474 - accuracy: 0.8333\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8139 - accuracy: 0.8500\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7826 - accuracy: 0.8583\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7535 - accuracy: 0.8417\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7268 - accuracy: 0.8500\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7001 - accuracy: 0.8583\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6748 - accuracy: 0.8750\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6520 - accuracy: 0.8667\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6331 - accuracy: 0.8750\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6115 - accuracy: 0.8750\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5924 - accuracy: 0.8750\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5761 - accuracy: 0.8833\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5598 - accuracy: 0.8917\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5448 - accuracy: 0.9000\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5316 - accuracy: 0.9167\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5183 - accuracy: 0.9250\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5063 - accuracy: 0.9333\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4954 - accuracy: 0.9250\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.9167\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4751 - accuracy: 0.9333\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4647 - accuracy: 0.9333\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.9333\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4484 - accuracy: 0.9333\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.9333\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.9333\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.9500\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4147 - accuracy: 0.9583\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4071 - accuracy: 0.9667\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3989 - accuracy: 0.9667\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3915 - accuracy: 0.9583\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3843 - accuracy: 0.9500\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3769 - accuracy: 0.9500\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3699 - accuracy: 0.9750\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3650 - accuracy: 0.9583\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3562 - accuracy: 0.9667\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3512 - accuracy: 0.9667\n",
            "=========prediction========\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "[[0.00289229 0.27325663 0.72385114]\n",
            " [0.9417299  0.0519562  0.00631385]\n",
            " [0.00267813 0.4213855  0.5759364 ]\n",
            " [0.00129378 0.30083197 0.6978743 ]\n",
            " [0.00200033 0.35257477 0.6454249 ]\n",
            " [0.02474607 0.56387925 0.4113745 ]\n",
            " [0.0073876  0.3866183  0.605994  ]\n",
            " [0.9779874  0.01919916 0.00281349]\n",
            " [0.935329   0.05654691 0.00812404]\n",
            " [0.01021072 0.4817048  0.5080845 ]\n",
            " [0.87673086 0.10850094 0.01476813]\n",
            " [0.9007677  0.08537559 0.01385669]\n",
            " [0.9041793  0.0830024  0.01281828]\n",
            " [0.02012513 0.5536249  0.4262501 ]\n",
            " [0.0049538  0.28551978 0.7095264 ]\n",
            " [0.89852124 0.0882934  0.01318538]\n",
            " [0.05596807 0.6680106  0.27602124]\n",
            " [0.9255614  0.06329689 0.01114168]\n",
            " [0.8392957  0.13982157 0.02088269]\n",
            " [0.01097586 0.48952293 0.49950108]\n",
            " [0.940309   0.05128844 0.00840259]\n",
            " [0.00395898 0.2998347  0.69620633]\n",
            " [0.01819052 0.6403298  0.34147966]\n",
            " [0.9022861  0.08459255 0.01312139]\n",
            " [0.8790674  0.10412423 0.01680842]\n",
            " [0.94455457 0.04753241 0.00791306]\n",
            " [0.81792915 0.15665203 0.02541877]\n",
            " [0.9661917  0.02903742 0.00477078]\n",
            " [0.9113371  0.078954   0.00970888]\n",
            " [0.00503138 0.28842154 0.7065471 ]]\n",
            "=========evaluate========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 317 calls to <function Model.make_test_function.<locals>.test_function at 0x7f64f14cd5f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 309ms/step - loss: 0.2861 - accuracy: 0.9667\n",
            "[0.2861371338367462, 0.9666666388511658]\n",
            "1 2 3 4\n",
            "[[1.0, 2.0, 3.0, 4.0]]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "[[0.05682473 0.16255505 0.7806202 ]]\n",
            "모델이 예측한 값은  virginica  입니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5번\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = pd.read_csv(\"winequality-white.csv\", sep=';')\n",
        "\n",
        "'''df_input = df.loc[:, ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', \n",
        "                  'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', \n",
        "                  'pH', 'sulphates', 'alcohol']]'''\n",
        "\n",
        "df_input = df.loc[:, 'fixed acidity':'alcohol']\n",
        "df_target = df.loc[:, 'quality']\n",
        "\n",
        "x = df_input.to_numpy()\n",
        "y = df_target.to_numpy()\n",
        "\n",
        "print(type(x[0][0]))\n",
        "print(x.shape)\n",
        "print(x)\n",
        "print(y.shape)\n",
        "print(y)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Dense(64, activation='relu', input_shape=(11,))) # 입력층은 특징벡터\n",
        "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(11, activation='softmax'))\n",
        "\n",
        "# sparse_categorical_crossentropy : 자동으로 원핫 인코딩\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=100, batch_size = 16)\n",
        "print('=========prediction========')\n",
        "print(model.predict(x_test))\n",
        "print('=========evaluate========')\n",
        "print(model.evaluate(x_test, y_test))\n",
        "\n",
        "x_input = [list(map(float, input().split()))]\n",
        "print(x_input)\n",
        "# 7.2 0.7 0 1.9 0.07 11 34 0.99 3.5  0.5 9.3\n",
        "y_pred = model.predict(x_input)\n",
        "print(y_pred)\n",
        "\n",
        "print(\"y_max = \", max(y_pred[0]))\n",
        "print(\"max_index\", np.argmax(y_pred)) \n",
        "# np.argmax() : numpy array max index\n",
        "print(\"입력 데이터의 와인 품질은 \", np.argmax(y_pred), \" 입니다.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yu1gNXc60oko",
        "outputId": "ca1343a2-875b-488b-ea69-041930ed00b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.float64'>\n",
            "(4898, 11)\n",
            "[[ 7.    0.27  0.36 ...  3.    0.45  8.8 ]\n",
            " [ 6.3   0.3   0.34 ...  3.3   0.49  9.5 ]\n",
            " [ 8.1   0.28  0.4  ...  3.26  0.44 10.1 ]\n",
            " ...\n",
            " [ 6.5   0.24  0.19 ...  2.99  0.46  9.4 ]\n",
            " [ 5.5   0.29  0.3  ...  3.34  0.38 12.8 ]\n",
            " [ 6.    0.21  0.38 ...  3.26  0.32 11.8 ]]\n",
            "(4898,)\n",
            "[6 6 6 ... 6 7 6]\n",
            "Epoch 1/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.4859 - accuracy: 0.4461\n",
            "Epoch 2/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3452 - accuracy: 0.4510\n",
            "Epoch 3/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3157 - accuracy: 0.4505\n",
            "Epoch 4/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.3004 - accuracy: 0.4505\n",
            "Epoch 5/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2939 - accuracy: 0.4507\n",
            "Epoch 6/100\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 1.2891 - accuracy: 0.4510\n",
            "Epoch 7/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2871 - accuracy: 0.4513\n",
            "Epoch 8/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2847 - accuracy: 0.4505\n",
            "Epoch 9/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2773 - accuracy: 0.4513\n",
            "Epoch 10/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2819 - accuracy: 0.4505\n",
            "Epoch 11/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2825 - accuracy: 0.4502\n",
            "Epoch 12/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2787 - accuracy: 0.4505\n",
            "Epoch 13/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2771 - accuracy: 0.4505\n",
            "Epoch 14/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2798 - accuracy: 0.4505\n",
            "Epoch 15/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2761 - accuracy: 0.4502\n",
            "Epoch 16/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2763 - accuracy: 0.4505\n",
            "Epoch 17/100\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 1.2733 - accuracy: 0.4520\n",
            "Epoch 18/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2754 - accuracy: 0.4502\n",
            "Epoch 19/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2724 - accuracy: 0.4510\n",
            "Epoch 20/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2692 - accuracy: 0.4513\n",
            "Epoch 21/100\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 1.2691 - accuracy: 0.4474\n",
            "Epoch 22/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2700 - accuracy: 0.4502\n",
            "Epoch 23/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2686 - accuracy: 0.4513\n",
            "Epoch 24/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2678 - accuracy: 0.4497\n",
            "Epoch 25/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2659 - accuracy: 0.4523\n",
            "Epoch 26/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2628 - accuracy: 0.4571\n",
            "Epoch 27/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2626 - accuracy: 0.4518\n",
            "Epoch 28/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2607 - accuracy: 0.4546\n",
            "Epoch 29/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2551 - accuracy: 0.4500\n",
            "Epoch 30/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2576 - accuracy: 0.4576\n",
            "Epoch 31/100\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 1.2563 - accuracy: 0.4520\n",
            "Epoch 32/100\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 1.2537 - accuracy: 0.4530\n",
            "Epoch 33/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2515 - accuracy: 0.4569\n",
            "Epoch 34/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2518 - accuracy: 0.4533\n",
            "Epoch 35/100\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 1.2474 - accuracy: 0.4553\n",
            "Epoch 36/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2440 - accuracy: 0.4510\n",
            "Epoch 37/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2432 - accuracy: 0.4602\n",
            "Epoch 38/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2373 - accuracy: 0.4673\n",
            "Epoch 39/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2334 - accuracy: 0.4571\n",
            "Epoch 40/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2291 - accuracy: 0.4635\n",
            "Epoch 41/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.2229 - accuracy: 0.4666\n",
            "Epoch 42/100\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 1.2202 - accuracy: 0.4712\n",
            "Epoch 43/100\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 1.2178 - accuracy: 0.4594\n",
            "Epoch 44/100\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 1.2103 - accuracy: 0.4684\n",
            "Epoch 45/100\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 1.1992 - accuracy: 0.4727\n",
            "Epoch 46/100\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 1.1963 - accuracy: 0.4742\n",
            "Epoch 47/100\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 1.1860 - accuracy: 0.4671\n",
            "Epoch 48/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1844 - accuracy: 0.4668\n",
            "Epoch 49/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1698 - accuracy: 0.4865\n",
            "Epoch 50/100\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 1.1694 - accuracy: 0.4809\n",
            "Epoch 51/100\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 1.1550 - accuracy: 0.4842\n",
            "Epoch 52/100\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 1.1486 - accuracy: 0.4852\n",
            "Epoch 53/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1447 - accuracy: 0.4883\n",
            "Epoch 54/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1428 - accuracy: 0.4832\n",
            "Epoch 55/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1364 - accuracy: 0.4954\n",
            "Epoch 56/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1363 - accuracy: 0.4857\n",
            "Epoch 57/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1310 - accuracy: 0.4972\n",
            "Epoch 58/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1309 - accuracy: 0.4926\n",
            "Epoch 59/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1305 - accuracy: 0.5026\n",
            "Epoch 60/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1188 - accuracy: 0.5013\n",
            "Epoch 61/100\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 1.1279 - accuracy: 0.4824\n",
            "Epoch 62/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1214 - accuracy: 0.4934\n",
            "Epoch 63/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1156 - accuracy: 0.4997\n",
            "Epoch 64/100\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 1.1150 - accuracy: 0.4997\n",
            "Epoch 65/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1124 - accuracy: 0.4923\n",
            "Epoch 66/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1122 - accuracy: 0.4931\n",
            "Epoch 67/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1129 - accuracy: 0.5000\n",
            "Epoch 68/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0997 - accuracy: 0.5018\n",
            "Epoch 69/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1025 - accuracy: 0.5123\n",
            "Epoch 70/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1038 - accuracy: 0.5048\n",
            "Epoch 71/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1049 - accuracy: 0.5003\n",
            "Epoch 72/100\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 1.0984 - accuracy: 0.5097\n",
            "Epoch 73/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.1056 - accuracy: 0.5051\n",
            "Epoch 74/100\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 1.0980 - accuracy: 0.5087\n",
            "Epoch 75/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0910 - accuracy: 0.5130\n",
            "Epoch 76/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0916 - accuracy: 0.5130\n",
            "Epoch 77/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0950 - accuracy: 0.5125\n",
            "Epoch 78/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0953 - accuracy: 0.5087\n",
            "Epoch 79/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0869 - accuracy: 0.5253\n",
            "Epoch 80/100\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 1.1006 - accuracy: 0.5013\n",
            "Epoch 81/100\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 1.0868 - accuracy: 0.5158\n",
            "Epoch 82/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0857 - accuracy: 0.5202\n",
            "Epoch 83/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0865 - accuracy: 0.5168\n",
            "Epoch 84/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0842 - accuracy: 0.5163\n",
            "Epoch 85/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0880 - accuracy: 0.5219\n",
            "Epoch 86/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0842 - accuracy: 0.5151\n",
            "Epoch 87/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0768 - accuracy: 0.5260\n",
            "Epoch 88/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0826 - accuracy: 0.5232\n",
            "Epoch 89/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0809 - accuracy: 0.5334\n",
            "Epoch 90/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0738 - accuracy: 0.5273\n",
            "Epoch 91/100\n",
            "245/245 [==============================] - 1s 2ms/step - loss: 1.0800 - accuracy: 0.5217\n",
            "Epoch 92/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0770 - accuracy: 0.5240\n",
            "Epoch 93/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0733 - accuracy: 0.5235\n",
            "Epoch 94/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0800 - accuracy: 0.5171\n",
            "Epoch 95/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0753 - accuracy: 0.5273\n",
            "Epoch 96/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0748 - accuracy: 0.5255\n",
            "Epoch 97/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0695 - accuracy: 0.5339\n",
            "Epoch 98/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0692 - accuracy: 0.5260\n",
            "Epoch 99/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0704 - accuracy: 0.5339\n",
            "Epoch 100/100\n",
            "245/245 [==============================] - 1s 3ms/step - loss: 1.0672 - accuracy: 0.5281\n",
            "=========prediction========\n",
            "31/31 [==============================] - 0s 2ms/step\n",
            "[[4.18984424e-16 2.55597856e-16 2.30567620e-15 ... 4.69877310e-02\n",
            "  1.08975649e-03 4.66884958e-17]\n",
            " [6.34332378e-11 3.14123901e-11 1.07179847e-11 ... 1.06011778e-01\n",
            "  3.15012294e-03 2.51028560e-12]\n",
            " [6.22023049e-13 3.12844396e-13 2.68743388e-13 ... 8.64536986e-02\n",
            "  2.02830671e-03 2.73144612e-14]\n",
            " ...\n",
            " [4.98638470e-15 2.74631587e-15 3.27548996e-14 ... 2.91461349e-02\n",
            "  2.36055203e-04 1.81137191e-15]\n",
            " [1.51419486e-13 1.07614025e-13 3.29333913e-12 ... 2.00121868e-02\n",
            "  2.91594217e-04 2.23320033e-13]\n",
            " [1.91381716e-15 1.85695287e-15 2.46182577e-13 ... 1.82508416e-02\n",
            "  8.55184451e-04 3.31030090e-15]]\n",
            "=========evaluate========\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 1.1148 - accuracy: 0.4847\n",
            "[1.114811897277832, 0.48469388484954834]\n",
            "7.2 0.7 0 1.9 0.07 11 34 0.99 3.5  0.5 9.3\n",
            "[[7.2, 0.7, 0.0, 1.9, 0.07, 11.0, 34.0, 0.99, 3.5, 0.5, 9.3]]\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "[[2.0453376e-19 3.8966769e-20 2.4426806e-17 1.3563889e-01 3.6937737e-01\n",
            "  5.8504060e-02 4.3540862e-01 1.0081196e-03 6.2933243e-05 2.0976671e-15\n",
            "  9.6039469e-20]]\n",
            "y_max =  0.43540862\n",
            "max_index 6\n",
            "입력 데이터의 와인 품질은  6  입니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6번\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# txt to csv\n",
        "df = pd.read_csv('seeds_dataset.txt', delimiter = '\\t')\n",
        "\n",
        "print(df.head())\n",
        "df_input = df.loc[:, 'A':'LKG']\n",
        "df_target = df.loc[:, 'target']\n",
        "\n",
        "x = df_input.to_numpy()\n",
        "y = df_target.to_numpy()\n",
        "\n",
        "# 주어진 data target 범위 : 1~3 -> 0~2로 변경 (안하면 error!)\n",
        "for i in range(210):\n",
        "  y[i] -= 1\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=4)\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Dense(32, activation='relu', input_shape=(7,)))\n",
        "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(3, activation='softmax'))\n",
        "\n",
        "# sparse_categorical_crossentropy : 자동으로 원핫 인코딩\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=100, batch_size = 16)\n",
        "\n",
        "print('=========prediction========')\n",
        "print(model.predict(x_test))\n",
        "print('=========evaluate========')\n",
        "print(model.evaluate(x_test, y_test))\n",
        "\n",
        "x_input = [list(map(float, input().split()))]\n",
        "print(x_input)\n",
        "\n",
        "y_pred = model.predict(x_input)\n",
        "print(y_pred)\n",
        "\n",
        "print(\"y_max = \", max(y_pred[0]))\n",
        "print(\"max_index\", np.argmax(y_pred)) \n",
        "# np.argmax() : numpy array max index\n",
        "print(\"입력 데이터의 종자는 \", np.argmax(y_pred), \" 입니다.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RGLJBHTWcLl",
        "outputId": "b54d885e-4400-44f6-9be0-642aab56d98d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       A      P       C     LK     WK  A_Coef    LKG  target\n",
            "0  15.26  14.84  0.8710  5.763  3.312   2.221  5.220       1\n",
            "1  14.88  14.57  0.8811  5.554  3.333   1.018  4.956       1\n",
            "2  14.29  14.09  0.9050  5.291  3.337   2.699  4.825       1\n",
            "3  13.84  13.94  0.8955  5.324  3.379   2.259  4.805       1\n",
            "4  16.14  14.99  0.9034  5.658  3.562   1.355  5.175       1\n",
            "Epoch 1/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 4.7675 - accuracy: 0.4345\n",
            "Epoch 2/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 3.3767 - accuracy: 0.3929\n",
            "Epoch 3/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 2.0946 - accuracy: 0.5000\n",
            "Epoch 4/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 1.2395 - accuracy: 0.4167\n",
            "Epoch 5/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 1.0412 - accuracy: 0.4167\n",
            "Epoch 6/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 1.0117 - accuracy: 0.4048\n",
            "Epoch 7/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.9663 - accuracy: 0.6131\n",
            "Epoch 8/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.9580 - accuracy: 0.5893\n",
            "Epoch 9/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.9269 - accuracy: 0.6250\n",
            "Epoch 10/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.9001 - accuracy: 0.6548\n",
            "Epoch 11/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.8922 - accuracy: 0.6905\n",
            "Epoch 12/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.8694 - accuracy: 0.6548\n",
            "Epoch 13/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.8559 - accuracy: 0.6607\n",
            "Epoch 14/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.8369 - accuracy: 0.6964\n",
            "Epoch 15/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.8271 - accuracy: 0.6905\n",
            "Epoch 16/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.8084 - accuracy: 0.7679\n",
            "Epoch 17/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.8095 - accuracy: 0.6369\n",
            "Epoch 18/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.7910 - accuracy: 0.7500\n",
            "Epoch 19/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.7653 - accuracy: 0.7857\n",
            "Epoch 20/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.7584 - accuracy: 0.7500\n",
            "Epoch 21/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.7372 - accuracy: 0.7857\n",
            "Epoch 22/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.7204 - accuracy: 0.8155\n",
            "Epoch 23/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.7114 - accuracy: 0.7738\n",
            "Epoch 24/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.7028 - accuracy: 0.8155\n",
            "Epoch 25/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.7078 - accuracy: 0.6964\n",
            "Epoch 26/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.6724 - accuracy: 0.8393\n",
            "Epoch 27/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.6656 - accuracy: 0.8036\n",
            "Epoch 28/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.6504 - accuracy: 0.8095\n",
            "Epoch 29/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.6344 - accuracy: 0.8393\n",
            "Epoch 30/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.6398 - accuracy: 0.7917\n",
            "Epoch 31/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.6310 - accuracy: 0.7500\n",
            "Epoch 32/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.6033 - accuracy: 0.8274\n",
            "Epoch 33/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.5907 - accuracy: 0.8512\n",
            "Epoch 34/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.5822 - accuracy: 0.8333\n",
            "Epoch 35/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.5717 - accuracy: 0.8393\n",
            "Epoch 36/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.5564 - accuracy: 0.8036\n",
            "Epoch 37/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5301 - accuracy: 0.8631\n",
            "Epoch 38/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.5284 - accuracy: 0.8571\n",
            "Epoch 39/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.5152 - accuracy: 0.8512\n",
            "Epoch 40/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.5109 - accuracy: 0.8393\n",
            "Epoch 41/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.4931 - accuracy: 0.8571\n",
            "Epoch 42/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.4807 - accuracy: 0.8214\n",
            "Epoch 43/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.4750 - accuracy: 0.8869\n",
            "Epoch 44/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.4609 - accuracy: 0.8810\n",
            "Epoch 45/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.4527 - accuracy: 0.8512\n",
            "Epoch 46/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.4420 - accuracy: 0.8810\n",
            "Epoch 47/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.4298 - accuracy: 0.8810\n",
            "Epoch 48/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.8810\n",
            "Epoch 49/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.4194 - accuracy: 0.8810\n",
            "Epoch 50/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.4138 - accuracy: 0.8512\n",
            "Epoch 51/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.4112 - accuracy: 0.8690\n",
            "Epoch 52/100\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.3987 - accuracy: 0.8690\n",
            "Epoch 53/100\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.3886 - accuracy: 0.8810\n",
            "Epoch 54/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.3809 - accuracy: 0.8810\n",
            "Epoch 55/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.3788 - accuracy: 0.8810\n",
            "Epoch 56/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.3730 - accuracy: 0.8929\n",
            "Epoch 57/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.3733 - accuracy: 0.8750\n",
            "Epoch 58/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.3763 - accuracy: 0.8810\n",
            "Epoch 59/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.3522 - accuracy: 0.8810\n",
            "Epoch 60/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.3671 - accuracy: 0.8512\n",
            "Epoch 61/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.3669 - accuracy: 0.8810\n",
            "Epoch 62/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.3648 - accuracy: 0.8571\n",
            "Epoch 63/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.3404 - accuracy: 0.9048\n",
            "Epoch 64/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.3377 - accuracy: 0.8690\n",
            "Epoch 65/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3356 - accuracy: 0.8750\n",
            "Epoch 66/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.3401 - accuracy: 0.8571\n",
            "Epoch 67/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.3244 - accuracy: 0.8869\n",
            "Epoch 68/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.3376 - accuracy: 0.8869\n",
            "Epoch 69/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.3357 - accuracy: 0.8690\n",
            "Epoch 70/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.3210 - accuracy: 0.8869\n",
            "Epoch 71/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.3187 - accuracy: 0.8810\n",
            "Epoch 72/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.3050 - accuracy: 0.8929\n",
            "Epoch 73/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.3198 - accuracy: 0.8810\n",
            "Epoch 74/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.3150 - accuracy: 0.9048\n",
            "Epoch 75/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.2995 - accuracy: 0.8988\n",
            "Epoch 76/100\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.3073 - accuracy: 0.8810\n",
            "Epoch 77/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.2995 - accuracy: 0.8869\n",
            "Epoch 78/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.2899 - accuracy: 0.9048\n",
            "Epoch 79/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.3016 - accuracy: 0.8929\n",
            "Epoch 80/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.3035 - accuracy: 0.8810\n",
            "Epoch 81/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.2940 - accuracy: 0.8869\n",
            "Epoch 82/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.2891 - accuracy: 0.9048\n",
            "Epoch 83/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.2922 - accuracy: 0.8929\n",
            "Epoch 84/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.2824 - accuracy: 0.8988\n",
            "Epoch 85/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.2756 - accuracy: 0.8988\n",
            "Epoch 86/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.2774 - accuracy: 0.9107\n",
            "Epoch 87/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.2840 - accuracy: 0.9048\n",
            "Epoch 88/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.2779 - accuracy: 0.9107\n",
            "Epoch 89/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.2758 - accuracy: 0.8988\n",
            "Epoch 90/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.2779 - accuracy: 0.8988\n",
            "Epoch 91/100\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2679 - accuracy: 0.8988\n",
            "Epoch 92/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.2690 - accuracy: 0.9107\n",
            "Epoch 93/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.2680 - accuracy: 0.8988\n",
            "Epoch 94/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.2647 - accuracy: 0.8929\n",
            "Epoch 95/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.2624 - accuracy: 0.8988\n",
            "Epoch 96/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.2681 - accuracy: 0.9048\n",
            "Epoch 97/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.2645 - accuracy: 0.8988\n",
            "Epoch 98/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.2581 - accuracy: 0.8810\n",
            "Epoch 99/100\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.2700 - accuracy: 0.8810\n",
            "Epoch 100/100\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.2649 - accuracy: 0.9048\n",
            "=========prediction========\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "[[8.98543119e-01 9.18407068e-02 9.61618777e-03]\n",
            " [2.51902223e-01 2.75242366e-02 7.20573545e-01]\n",
            " [1.12114903e-02 9.88612592e-01 1.75999056e-04]\n",
            " [8.35060000e-01 1.57451212e-01 7.48881372e-03]\n",
            " [1.91804357e-02 9.80608821e-01 2.10819780e-04]\n",
            " [9.48099017e-01 4.58172709e-02 6.08360814e-03]\n",
            " [2.23239679e-02 9.77426589e-01 2.49452278e-04]\n",
            " [7.78210117e-03 1.35312497e-04 9.92082596e-01]\n",
            " [3.62181254e-02 1.85339549e-03 9.61928427e-01]\n",
            " [2.90855695e-03 9.97046232e-01 4.51201122e-05]\n",
            " [5.07840551e-02 2.23624113e-04 9.48992372e-01]\n",
            " [9.54401731e-01 2.84735374e-02 1.71245895e-02]\n",
            " [5.82879456e-03 3.60804588e-05 9.94135082e-01]\n",
            " [2.92594023e-02 9.70569670e-01 1.71017396e-04]\n",
            " [9.65274274e-01 2.33234316e-02 1.14022726e-02]\n",
            " [1.17718079e-03 9.98805106e-01 1.76053236e-05]\n",
            " [7.48371147e-03 7.18604497e-05 9.92444396e-01]\n",
            " [7.74276793e-01 2.48372834e-02 2.00885937e-01]\n",
            " [4.62393416e-03 2.84090966e-05 9.95347679e-01]\n",
            " [4.39866483e-02 2.88278842e-03 9.53130603e-01]\n",
            " [8.65928769e-01 6.04280978e-02 7.36430660e-02]\n",
            " [3.34549904e-01 6.57129705e-01 8.32047500e-03]\n",
            " [1.39880642e-01 1.69990826e-02 8.43120277e-01]\n",
            " [1.35958761e-01 8.61794829e-01 2.24653259e-03]\n",
            " [2.99922358e-02 9.69888926e-01 1.18891534e-04]\n",
            " [5.88756353e-02 2.07171123e-03 9.39052582e-01]\n",
            " [9.61514711e-01 1.99957453e-02 1.84895974e-02]\n",
            " [9.31438580e-02 9.06218886e-01 6.37306948e-04]\n",
            " [6.73650252e-03 6.97587820e-05 9.93193686e-01]\n",
            " [5.74955404e-01 1.91654246e-02 4.05879170e-01]\n",
            " [3.92526776e-01 5.53032663e-03 6.01942897e-01]\n",
            " [4.93793795e-03 9.94957030e-01 1.05099214e-04]\n",
            " [9.39563274e-01 3.08631249e-02 2.95736361e-02]\n",
            " [8.34896028e-01 1.48013413e-01 1.70904435e-02]\n",
            " [9.74417925e-02 9.01954532e-01 6.03767228e-04]\n",
            " [7.06293155e-03 9.92816687e-01 1.20386343e-04]\n",
            " [7.22044766e-01 2.37769589e-01 4.01856117e-02]\n",
            " [7.49023855e-01 2.34716862e-01 1.62593164e-02]\n",
            " [2.53200419e-02 1.88429491e-04 9.74491477e-01]\n",
            " [3.38298804e-03 9.96572137e-01 4.48685860e-05]\n",
            " [3.58036906e-01 6.29256904e-01 1.27061931e-02]\n",
            " [4.54881229e-03 1.73167355e-04 9.95278001e-01]]\n",
            "=========evaluate========\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1491 - accuracy: 0.9762\n",
            "[0.1490667462348938, 0.976190447807312]\n",
            "15 14 0.87 5.7 3.3 2.2 5.2\n",
            "[[15.0, 14.0, 0.87, 5.7, 3.3, 2.2, 5.2]]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "[[0.66860396 0.3238465  0.00754955]]\n",
            "y_max =  0.66860396\n",
            "max_index 0\n",
            "입력 데이터의 종자는  0  입니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7번\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "\n",
        "fashion_data = tf.keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_data.load_data()\n",
        "train_images = train_images.reshape((60000, 28, 28, 1)) # RGB = 1?\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))\n",
        "\n",
        "print(train_images.shape)\n",
        "print(train_labels.shape)\n",
        "\n",
        "# 픽셀 값 0~1 정규화\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "model = models.Sequential()\n",
        "# Convolution layer\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1))) # 3 x 3 filter, 32개 node\n",
        "model.add(layers.MaxPool2D(2, 2))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPool2D(2, 2))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "# Fully Connected layer\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax')) # class 종류 : 10개(0~9)\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, epochs=3)\n",
        "print('====================prediction==================')\n",
        "print(model.predict(test_images))\n",
        "print('=====================evaluate===================')\n",
        "print(model.evaluate(test_images, test_labels))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRLH-SjSpU6V",
        "outputId": "b1e45c4a-93ff-400f-a035-5fb1dfbdc510"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28, 1)\n",
            "(60000,)\n",
            "Epoch 1/3\n",
            "1875/1875 [==============================] - 63s 33ms/step - loss: 0.5201 - accuracy: 0.8089\n",
            "Epoch 2/3\n",
            "1875/1875 [==============================] - 62s 33ms/step - loss: 0.3344 - accuracy: 0.8782\n",
            "Epoch 3/3\n",
            "1875/1875 [==============================] - 62s 33ms/step - loss: 0.2817 - accuracy: 0.8961\n",
            "====================prediction==================\n",
            "313/313 [==============================] - 4s 11ms/step\n",
            "[[6.6032306e-05 4.5305860e-06 7.1584300e-06 ... 1.4386858e-02\n",
            "  3.2411882e-04 9.8128098e-01]\n",
            " [2.5177450e-04 2.8281391e-07 9.9691409e-01 ... 7.8678823e-08\n",
            "  2.0267564e-05 3.2469547e-09]\n",
            " [8.4455542e-06 9.9997908e-01 4.6497679e-08 ... 1.9565018e-11\n",
            "  6.2730674e-06 1.5732767e-09]\n",
            " ...\n",
            " [1.9131834e-05 3.9092576e-08 9.1657978e-07 ... 1.3368487e-08\n",
            "  9.9986053e-01 8.2958029e-10]\n",
            " [1.6607857e-05 9.9992436e-01 5.5345506e-08 ... 7.2823490e-11\n",
            "  7.6030365e-06 8.1185725e-09]\n",
            " [6.1545469e-04 2.7561244e-05 4.0415104e-04 ... 2.8021983e-03\n",
            "  2.3051683e-02 6.4079824e-04]]\n",
            "=====================evaluate===================\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.3148 - accuracy: 0.8854\n",
            "[0.3147745728492737, 0.8853999972343445]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction\n",
        "y_pred = model.predict(test_images)\n",
        "print(\"예측값 = \", np.argmax(y_pred[0]))\n",
        "print(\"정답값 = \", test_labels[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARL_WluCJNkS",
        "outputId": "2b1f95a7-6a1d-4646-9774-fb803692f6bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 3s 11ms/step\n",
            "예측값 =  9\n",
            "정답값 =  9\n"
          ]
        }
      ]
    }
  ]
}